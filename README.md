**Convert from Pytorch(Mobilenet_v2)=>Onnx=>TF(SavedModel)=>TFLite(Float32)=>TFLite(quantized)**

